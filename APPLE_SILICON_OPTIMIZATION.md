# üçé Apple Silicon GPU Optimization Guide

Complete guide to enable GPU acceleration for **3-6x faster** image processing on M1/M2/M3 Macs.

---

## üìä Performance Improvements

| Component | Before (CPU) | After (GPU) | Speedup |
|-----------|--------------|-------------|---------|
| **CLIP Embeddings** | 2-3s per image | 0.5-1s per image | **3-6x faster** |
| **Sharp Processing** | ~100ms per image | ~50ms per image | **2x faster** |
| **Overall Workflow** | Baseline | 30-50% faster | **~40% faster** |

---

## ‚úÖ Quick Start (One Command)

```bash
# Install everything and verify GPU acceleration
npm run optimize
```

This will:
1. ‚úÖ Install PyTorch with MPS (Apple Silicon GPU) support
2. ‚úÖ Install all Python dependencies
3. ‚úÖ Rebuild native modules for Apple Silicon
4. ‚úÖ Verify GPU is working correctly

---

## üìã Manual Installation Steps

### 1. Set Up Python Virtual Environment

```bash
# Install PyTorch with Apple Silicon GPU support
npm run setup-python

# Expected output:
# üöÄ SUCCESS! Apple Silicon GPU acceleration is ENABLED!
```

### 2. Verify GPU Acceleration

```bash
# Run comprehensive GPU test
npm run verify-gpu

# Expected output:
# ‚úÖ ALL TESTS PASSED - GPU READY!
```

### 3. Rebuild Native Modules

```bash
# Ensure Sharp uses Apple Silicon binaries
npm run rebuild-native
```

### 4. Start the Application

```bash
# GPU will be automatically detected
npm start

# Look for this in the terminal:
# üöÄ Apple Silicon GPU (MPS) is ENABLED!
# üöÄ Using Apple Silicon GPU (MPS) for CLIP embeddings
```

---

## üîç Verification

### Check GPU Status Anytime

```bash
# Quick GPU check
python3 -c "import torch; print(f'MPS Available: {torch.backends.mps.is_available()}')"

# Full verification
npm run verify-gpu
```

### Check Electron Architecture

```bash
# Should output: "Mach-O 64-bit executable arm64"
file node_modules/electron/dist/Electron.app/Contents/MacOS/Electron
```

### Check Sharp Architecture

```bash
# Should show @img/sharp-darwin-arm64
npm list @img/sharp-darwin-arm64
```

---

## üß™ Testing GPU Performance

### Test CLIP Service

```bash
# Start CLIP service manually to test
npm run test-clip

# Should show:
# üöÄ Using Apple Silicon GPU (MPS) for CLIP embeddings
# ‚úÖ CLIP model ready on MPS!
```

### Performance Benchmark

Create a test file `test_performance.py`:

```python
import torch
import time

device = torch.device("mps")

# CPU test
x_cpu = torch.randn(2000, 2000)
y_cpu = torch.randn(2000, 2000)
start = time.time()
z_cpu = torch.matmul(x_cpu, y_cpu)
cpu_time = time.time() - start

# GPU test
x_gpu = torch.randn(2000, 2000, device=device)
y_gpu = torch.randn(2000, 2000, device=device)
start = time.time()
z_gpu = torch.matmul(x_gpu, y_gpu)
gpu_time = time.time() - start

print(f"CPU Time: {cpu_time:.3f}s")
print(f"GPU Time: {gpu_time:.3f}s")
print(f"Speedup: {cpu_time / gpu_time:.2f}x")
```

Run with:
```bash
source venv/bin/activate && python3 test_performance.py
```

---

## üõ†Ô∏è Troubleshooting

### GPU Not Detected

**Issue**: `‚ö†Ô∏è GPU acceleration not available - using CPU`

**Solutions**:
1. **Check macOS version**:
   ```bash
   sw_vers -productVersion
   # Should be 12.3 or later
   ```

2. **Check architecture**:
   ```bash
   uname -m
   # Should be arm64 (not x86_64)
   ```

3. **Reinstall PyTorch with MPS**:
   ```bash
   source venv/bin/activate
   pip3 uninstall torch torchvision
   pip3 install --upgrade torch torchvision
   ```

4. **Verify Python is not running under Rosetta**:
   ```bash
   python3 -c "import platform; print(platform.machine())"
   # Should be arm64
   ```

### CLIP Service Fails to Start

**Issue**: `ModuleNotFoundError` or service doesn't start

**Solutions**:
1. **Reinstall dependencies**:
   ```bash
   npm run clean
   npm run setup-python
   ```

2. **Check virtual environment**:
   ```bash
   ls -la venv/bin/python3
   # Should exist
   ```

3. **Test CLIP manually**:
   ```bash
   source venv/bin/activate
   python3 -c "from transformers import CLIPModel; print('OK')"
   ```

### Electron Running Under Rosetta

**Issue**: Electron shows `x86_64` instead of `arm64`

**Solution**:
```bash
npm uninstall electron
npm install electron --arch=arm64 --platform=darwin
npm rebuild
```

### Sharp Using Wrong Architecture

**Issue**: Sharp not using native ARM64 binaries

**Solution**:
```bash
npm uninstall sharp
npm install sharp --arch=arm64 --platform=darwin
```

---

## üìà Expected Console Output

When everything is optimized, you should see:

```
üîç Checking Apple Silicon GPU (MPS) status...
üöÄ Apple Silicon GPU (MPS) is ENABLED!
   PyTorch version: 2.1.0
   CLIP embeddings will use GPU acceleration (3-6x faster)

Starting CLIP similarity service...
======================================================================
üé® Loading CLIP Model...
======================================================================
üöÄ Using Apple Silicon GPU (MPS) for CLIP embeddings
   Expected speedup: 3-6x faster than CPU

üì• Downloading model (if not cached)...
üìç Moving model to MPS...

‚úÖ CLIP model ready on MPS!
   PyTorch version: 2.1.0
   Model parameters: 151,277,313
======================================================================
```

---

## üîß Advanced Configuration

### Custom Python Path

If you have a different Python installation:

```bash
# Edit install_pytorch_mps.sh and change:
# python3 -> /path/to/your/python3
```

### MPS Memory Management

If you run into memory issues:

```python
# Add to similarity_service.py after model load:
torch.mps.empty_cache()  # Clear GPU memory
```

### Force CPU Mode (for Testing)

```bash
# Temporarily disable GPU
export PYTORCH_ENABLE_MPS_FALLBACK=1
npm start
```

---

## üìö Additional Resources

- **PyTorch MPS Documentation**: https://pytorch.org/docs/stable/notes/mps.html
- **Apple Metal Performance Shaders**: https://developer.apple.com/metal/
- **Sharp Documentation**: https://sharp.pixelplumbing.com/
- **Electron on Apple Silicon**: https://www.electronjs.org/docs/latest/tutorial/apple-silicon

---

## üéØ Optimization Checklist

- [ ] PyTorch with MPS installed (`npm run setup-python`)
- [ ] GPU verification passed (`npm run verify-gpu`)
- [ ] Native modules rebuilt (`npm run rebuild-native`)
- [ ] Electron running on ARM64 (`file node_modules/electron/...`)
- [ ] Sharp using ARM64 binaries (`npm list @img/sharp-darwin-arm64`)
- [ ] CLIP service shows "Using Apple Silicon GPU (MPS)"
- [ ] Main process logs show "üöÄ Apple Silicon GPU (MPS) is ENABLED!"

---

## üí° Tips

1. **First Launch**: First time loading CLIP model will download ~600MB (cached after)
2. **Memory**: GPU acceleration uses ~2-3GB VRAM
3. **Temperature**: GPU will warm up during processing (normal)
4. **Battery**: GPU acceleration uses more power - plug in for long sessions
5. **Monitoring**: Use Activity Monitor > GPU tab to watch usage

---

## üêõ Known Issues

### Issue: "slow image processor" Warning

**Message**: `Using a slow image processor as use_fast is unset...`

**Status**: Cosmetic warning only - doesn't affect performance

**Fix** (optional):
```python
# In similarity_service.py, change:
processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
# To:
processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32", use_fast=True)
```

### Issue: urllib3 Warning

**Message**: `urllib3 v2 only supports OpenSSL 1.1.1+...`

**Status**: Cosmetic warning only - doesn't affect functionality

---

## üìû Support

If you encounter issues not covered here:

1. Check `z_Logs and traces/app.log` for errors
2. Run `npm run verify-gpu` for diagnostic output
3. Check if running under Rosetta: `sysctl sysctl.proc_translated`
   - Should output `0` (native ARM64)

---

**‚úÖ Once optimized, you're ready to process images at maximum speed!**

